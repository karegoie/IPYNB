{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c653dcff-1c29-4ab9-b30c-8071b8b8f921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 10.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import Bio.SeqIO as SeqIO\n",
    "from tqdm import tqdm\n",
    "import itertools \n",
    "import random\n",
    "\n",
    "L = 1000\n",
    "data_tmp = {}\n",
    "ctg_index = {}\n",
    "\n",
    "with open(\"./ecoliquadra.fna\", \"r\") as f:\n",
    "    for record in tqdm(SeqIO.parse(f, \"fasta\")):\n",
    "        data_tmp[record.id] = str(record.seq).upper()\n",
    "\n",
    "def count_kmers(read, k):\n",
    "    \"\"\"Count kmer occurrences in a given read.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    read : string\n",
    "        A single DNA sequence.\n",
    "    k : int\n",
    "        The value of k for which to count kmers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    counts : dictionary, {'string': int}\n",
    "        A dictionary of counts keyed by their individual kmers (strings\n",
    "        of length k).\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> count_kmers(\"GATGAT\", 3)\n",
    "    {'ATG': 1, 'GAT': 2, 'TGA': 1}\n",
    "    \"\"\"\n",
    "    # Start with an empty dictionary\n",
    "    counts = {}\n",
    "    nucleotides = ['A', 'T', 'G', 'C']\n",
    "    # Add the kmer to the dictionary if it's not there\n",
    "    for i in itertools.product(nucleotides, repeat=k):\n",
    "        counts[\"\".join(i)] = 0\n",
    "    # Calculate how many kmers of length k there are\n",
    "    num_kmers = len(read) - k + 1\n",
    "    # Loop over the kmer start positions\n",
    "    for kmer in window(read, n=k):\n",
    "        kmer = \"\".join(kmer)\n",
    "        if kmer not in counts:\n",
    "            continue\n",
    "        # Increment the count for this kmer\n",
    "        counts[kmer] += 1\n",
    "    # Return the final counts\n",
    "    return counts\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from numpy import (array, unravel_index, nditer, linalg, random, subtract,\n",
    "                   power, exp, pi, zeros, arange, outer, meshgrid, dot)\n",
    "from collections import defaultdict\n",
    "from warnings import warn\n",
    "\n",
    "\n",
    "def fast_norm(x):\n",
    "    \"\"\"Returns norm-2 of a 1-D numpy array.\n",
    "\n",
    "    * faster than linalg.norm in case of 1-D arrays (numpy 1.9.2rc1).\n",
    "    \"\"\"\n",
    "    return sqrt(dot(x, x.T))\n",
    "\n",
    "\n",
    "class Som:\n",
    "    def __init__(self,x,y,input_len,sigma=1.0,learning_rate=0.5,random_seed=None):\n",
    "        \"\"\"\n",
    "            Initializes a Self Organizing Maps.\n",
    "            x,y - dimensions of the SOM\n",
    "            input_len - number of the elements of the vectors in input\n",
    "            sigma - spread of the neighborhood function (Gaussian), needs to be adequate to the dimensions of the map.\n",
    "            (at the iteration t we have sigma(t) = sigma / (1 + t/T) where T is #num_iteration/2)\n",
    "            learning_rate - initial learning rate\n",
    "            (at the iteration t we have learning_rate(t) = learning_rate / (1 + t/T) where T is #num_iteration/2)\n",
    "            random_seed, random seed to use.\n",
    "        \"\"\"\n",
    "        if sigma >= x/2.0 or sigma >= y/2.0:\n",
    "            warn('Warning: sigma is too high for the dimension of the map.')\n",
    "        if random_seed:\n",
    "            self.random_generator = random.RandomState(random_seed)\n",
    "        else:\n",
    "            self.random_generator = random.RandomState(random_seed)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.sigma = sigma\n",
    "        self.weights = self.random_generator.rand(x,y,input_len)*2-1 # random initialization\n",
    "        self.weights = array([v/linalg.norm(v) for v in self.weights]) # normalization\n",
    "        self.activation_map = zeros((x,y))\n",
    "        self.neigx = arange(x)\n",
    "        self.neigy = arange(y) # used to evaluate the neighborhood function\n",
    "        self.neighborhood = self.gaussian\n",
    "\n",
    "    def _activate(self,x):\n",
    "        \"\"\" Updates matrix activation_map, in this matrix the element i,j is the response of the neuron i,j to x \"\"\"\n",
    "        s = subtract(x,self.weights) # x - w\n",
    "        it = nditer(self.activation_map, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            self.activation_map[it.multi_index] = fast_norm(s[it.multi_index]) # || x - w ||\n",
    "            it.iternext()\n",
    "\n",
    "    def activate(self,x):\n",
    "        \"\"\" Returns the activation map to x \"\"\"\n",
    "        self._activate(x)\n",
    "        return self.activation_map\n",
    "\n",
    "    def gaussian(self,c,sigma):\n",
    "        \"\"\" Returns a Gaussian centered in c \"\"\"\n",
    "        d = 2*pi*sigma*sigma\n",
    "        ax = exp(-power(self.neigx-c[0],2)/d)\n",
    "        ay = exp(-power(self.neigy-c[1],2)/d)\n",
    "        return outer(ax,ay) # the external product gives a matrix\n",
    "\n",
    "    def diff_gaussian(self,c,sigma):\n",
    "        \"\"\" Mexican hat centered in c (unused) \"\"\"\n",
    "        xx,yy = meshgrid(self.neigx,self.neigy)\n",
    "        p = power(xx-c[0],2) + power(yy-c[1],2)\n",
    "        d = 2*pi*sigma*sigma\n",
    "        return exp(-(p)/d)*(1-2/d*p)\n",
    "\n",
    "    def winner(self,x):\n",
    "        \"\"\" Computes the coordinates of the winning neuron for the sample x \"\"\"\n",
    "        self._activate(x)\n",
    "        return unravel_index(self.activation_map.argmin(),self.activation_map.shape)\n",
    "\n",
    "    def update(self,x,win,t):\n",
    "        \"\"\"\n",
    "            Updates the weights of the neurons.\n",
    "            x - current pattern to learn\n",
    "            win - position of the winning neuron for x (array or tuple).\n",
    "            t - iteration index\n",
    "        \"\"\"\n",
    "        # eta(t) = eta(0) / (1 + t/T) \n",
    "        # keeps the learning rate nearly constant for the first T iterations and then adjusts it\n",
    "        eta = self.learning_rate/(1+t/self.T)\n",
    "        sig = self.sigma/(1+t/self.T) # sigma and learning rate decrease with the same rule\n",
    "        g = self.neighborhood(win,sig)*eta # improves the performances\n",
    "        it = nditer(g, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            # eta * neighborhood_function * (x-w)\n",
    "            self.weights[it.multi_index] += g[it.multi_index]*(x-self.weights[it.multi_index])            \n",
    "            # normalization\n",
    "            self.weights[it.multi_index] = self.weights[it.multi_index] / fast_norm(self.weights[it.multi_index])\n",
    "            it.iternext()\n",
    "\n",
    "    def quantization(self,data):\n",
    "        \"\"\" Assigns a code book (weights vector of the winning neuron) to each sample in data. \"\"\"\n",
    "        q = zeros(data.shape)\n",
    "        for i,x in enumerate(data):\n",
    "            q[i] = self.weights[self.winner(x)]\n",
    "        return q\n",
    "\n",
    "\n",
    "    def random_weights_init(self,data):\n",
    "        \"\"\" Initializes the weights of the SOM picking random samples from data \"\"\"\n",
    "        it = nditer(self.activation_map, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            self.weights[it.multi_index] = data[int(self.random_generator.rand()*len(data)-1)]\n",
    "            self.weights[it.multi_index] = self.weights[it.multi_index]/fast_norm(self.weights[it.multi_index])\n",
    "            it.iternext()\n",
    "\n",
    "    def train_random(self,data,num_iteration):        \n",
    "        \"\"\" Trains the SOM picking samples at random from data \"\"\"\n",
    "        self._init_T(num_iteration)        \n",
    "        for iteration in range(num_iteration):\n",
    "            rand_i = int(round(self.random_generator.rand()*len(data)-1)) # pick a random sample\n",
    "            self.update(data[rand_i],self.winner(data[rand_i]),iteration)\n",
    "\n",
    "    def train_batch(self,data,num_iteration):\n",
    "        \"\"\" Trains using all the vectors in data sequentially \"\"\"\n",
    "        self._init_T(len(data)*num_iteration)\n",
    "        iteration = 0\n",
    "        while iteration < num_iteration:\n",
    "            idx = iteration % (len(data)-1)\n",
    "            self.update(data[idx],self.winner(data[idx]),iteration)\n",
    "            iteration += 1\n",
    "\n",
    "    def _init_T(self,num_iteration):\n",
    "        \"\"\" Initializes the parameter T needed to adjust the learning rate \"\"\"\n",
    "        self.T = num_iteration/2 # keeps the learning rate nearly constant for the first half of the iterations\n",
    "\n",
    "    def distance_map(self):\n",
    "        \"\"\" Returns the average distance map of the weights.\n",
    "            (Each mean is normalized in order to sum up to 1) \"\"\"\n",
    "        um = zeros((self.weights.shape[0],self.weights.shape[1]))\n",
    "        it = nditer(um, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            for ii in range(it.multi_index[0]-1,it.multi_index[0]+2):\n",
    "                for jj in range(it.multi_index[1]-1,it.multi_index[1]+2):\n",
    "                    if ii >= 0 and ii < self.weights.shape[0] and jj >= 0 and jj < self.weights.shape[1]:\n",
    "                        um[it.multi_index] += fast_norm(self.weights[ii,jj,:]-self.weights[it.multi_index])\n",
    "            it.iternext()\n",
    "        um = um/um.max()\n",
    "        return um\n",
    "\n",
    "    def activation_response(self,data):\n",
    "        \"\"\" \n",
    "            Returns a matrix where the element i,j is the number of times\n",
    "            that the neuron i,j have been winner.\n",
    "        \"\"\"\n",
    "        a = zeros((self.weights.shape[0],self.weights.shape[1]))\n",
    "        for x in data:\n",
    "            a[self.winner(x)] += 1\n",
    "        return a\n",
    "\n",
    "    def quantization_error(self,data):\n",
    "        \"\"\" \n",
    "            Returns the quantization error computed as the average distance between\n",
    "            each input sample and its best matching unit.            \n",
    "        \"\"\"\n",
    "        error = 0\n",
    "        for x in data:\n",
    "            error += fast_norm(x-self.weights[self.winner(x)])\n",
    "        return error/len(data)\n",
    "\n",
    "    def win_map(self,data):\n",
    "        \"\"\"\n",
    "            Returns a dictionary wm where wm[(i,j)] is a list with all the patterns\n",
    "            that have been mapped in the position i,j.\n",
    "        \"\"\"\n",
    "        winmap = defaultdict(list)\n",
    "        for x in data:\n",
    "            winmap[self.winner(x)].append(x)\n",
    "        return winmap\n",
    "\n",
    "### unit tests\n",
    "from numpy.testing import assert_almost_equal, assert_array_almost_equal, assert_array_equal\n",
    "\n",
    "class TestSom:\n",
    "    def setup_method(self, method):\n",
    "        self.som = Som(5,5,1)\n",
    "        for w in self.som.weights: # checking weights normalization\n",
    "            assert_almost_equal(1.0,linalg.norm(w))\n",
    "        self.som.weights = zeros((5,5)) # fake weights\n",
    "        self.som.weights[2,3] = 5.0\n",
    "        self.som.weights[1,1] = 2.0\n",
    "\n",
    "    def test_fast_norm(self):\n",
    "        assert fast_norm(array([1,3])) == sqrt(1+9)\n",
    "\n",
    "    def test_gaussian(self):\n",
    "        bell = self.som.gaussian((2,2),1)\n",
    "        assert bell.max() == 1.0\n",
    "        assert bell.argmax() == 12  # unravel(12) = (2,2)\n",
    "\n",
    "    def test_win_map(self):\n",
    "        winners = self.som.win_map([5.0,2.0])\n",
    "        assert winners[(2,3)][0] == 5.0\n",
    "        assert winners[(1,1)][0] == 2.0\n",
    "\n",
    "    def test_activation_reponse(self):\n",
    "        response = self.som.activation_response([5.0,2.0])\n",
    "        assert response[2,3] == 1\n",
    "        assert response[1,1] == 1\n",
    "\n",
    "    def test_activate(self):\n",
    "        assert self.som.activate(5.0).argmin() == 13.0  # unravel(13) = (2,3)\n",
    "     \n",
    "    def test_quantization_error(self):\n",
    "        self.som.quantization_error([5,2]) == 0.0\n",
    "        self.som.quantization_error([4,1]) == 0.5\n",
    "\n",
    "    def test_quantization(self):\n",
    "        q = self.som.quantization(array([4,2]))\n",
    "        assert q[0] == 5.0\n",
    "        assert q[1] == 2.0\n",
    "\n",
    "    def test_random_seed(self):\n",
    "        som1 = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
    "        som2 = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
    "        assert_array_almost_equal(som1.weights,som2.weights) # same initialization\n",
    "        data = random.rand(100,2)\n",
    "        som1 = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
    "        som1.train_random(data,10)\n",
    "        som2 = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
    "        som2.train_random(data,10)\n",
    "        assert_array_almost_equal(som1.weights,som2.weights) # same state after training\n",
    "\n",
    "    def test_train_batch(self):\n",
    "        som = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
    "        data = array([[4,2],[3,1]])\n",
    "        q1 = som.quantization_error(data)\n",
    "        som.train_batch(data,10)\n",
    "        assert q1 > som.quantization_error(data)\n",
    "\n",
    "    def test_train_random(self):\n",
    "        som = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
    "        data = array([[4,2],[3,1]])\n",
    "        q1 = som.quantization_error(data)\n",
    "        som.train_random(data,10)\n",
    "        assert q1 > som.quantization_error(data)\n",
    "\n",
    "    def test_random_weights_init(self):\n",
    "        som = Som(2,2,2,random_seed=1)\n",
    "        som.random_weights_init(array([[1.0,.0]]))\n",
    "        for w in som.weights:\n",
    "            assert_array_equal(w[0],array([1.0,.0]))\n",
    "\n",
    "import itertools\n",
    "def window(seq, n=2):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(itertools.islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result    \n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "\n",
    "M = 100\n",
    "K = 3\n",
    "L = 50\n",
    "kmer_datas = {}\n",
    "for k, v in tqdm(data_tmp.items()):\n",
    "    for i, p in enumerate(range(0, int(len(v)/L)*L, L)):\n",
    "        if (k, i) not in kmer_datas.keys(): kmer_datas[(k, i)] = []\n",
    "        kmer_datas[(k, i)] += list(count_kmers(v[p:p+L], K).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21b1b874-079d-475e-9d3b-bb44ef55f1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.93612645 1.        ]\n",
      " [0.95137657 0.94445394]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_kmer_datas = []\n",
    "\n",
    "for k, v in tqdm(data_tmp.items()):\n",
    "    kmer_data = list(count_kmers(v, K).values())\n",
    "    assert len(kmer_data) == 4**K\n",
    "    train_kmer_datas.append(kmer_data)\n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "X = sc.fit_transform(train_kmer_datas)\n",
    "\n",
    "cnt = 1\n",
    "som = Som(2, 2, 4**K, sigma=.001,learning_rate=1e-5)\n",
    "while som.distance_map().T.min() < 0.9:\n",
    "    print(f\"{cnt} trial\")\n",
    "    som = Som(2, 2, 4**K, sigma=.001,learning_rate=0.5)\n",
    "    #som = Som(2, 1, 4**K, sigma=.001,learning_rate=0.5)\n",
    "    som.random_weights_init(X)\n",
    "\n",
    "    som.train_random(X, 10000)\n",
    "    #som.train_batch(X, 10000)\n",
    "    cnt+=1\n",
    "print(som.distance_map().T)\n",
    "change = {(0,0) : 1, (0,1): -1, (1,0): 1j, (1,1): -1j}\n",
    "\n",
    "for k, g in zip(kmer_datas.keys(), X):\n",
    "    raw_spec[k] = [change[som.winner(i)] for i in g]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a34a4-bfd3-4195-8343-208c507a1f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20ce963e-30fe-4729-8509-ffab2100ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.96684611 1.        ]\n",
      " [0.95021288 0.908513  ]]\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [57], line 47\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#print(ctg)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#print(\"++++++++++++++++++++++++++++++++++\")\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#print(ctg)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#print(ctg.shape)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m ctg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([ctg1, np\u001b[38;5;241m.\u001b[39masarray(v)])\n\u001b[0;32m---> 47\u001b[0m cwtmatr, freqs \u001b[38;5;241m=\u001b[39m \u001b[43mpywt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcwt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcmor4-1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ma1 \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39mabsolute(np\u001b[38;5;241m.\u001b[39mmax(cwtmatr)):\n\u001b[1;32m     49\u001b[0m     ma1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabsolute(np\u001b[38;5;241m.\u001b[39mmax(cwtmatr))\n",
      "File \u001b[0;32m~/miniconda3/envs/notebook/lib/python3.10/site-packages/pywt/_cwt.py:158\u001b[0m, in \u001b[0;36mcwt\u001b[0;34m(data, scales, wavelet, sampling_period, method, axis)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m         conv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_psi_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;66;03m# batch convolution via loop\u001b[39;00m\n\u001b[1;32m    161\u001b[0m         conv_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/notebook/lib/python3.10/site-packages/numpy/core/numeric.py:844\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv cannot be empty\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 844\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pywt\n",
    "\n",
    "ridx = random.choice(len(raw_spec))\n",
    "ctg1 = np.asarray(list(raw_spec.values())[ridx])\n",
    "\n",
    "while True:\n",
    "    cnt +=1\n",
    "    ma1 = 0\n",
    "    ma2 = 0\n",
    "    best_list = []\n",
    "    for k, v in raw_spec.items():\n",
    "        if k in best_list: continue\n",
    "        #print(ctg)\n",
    "        #print(\"++++++++++++++++++++++++++++++++++\")\n",
    "        #print(ctg)\n",
    "        #print(ctg.shape)\n",
    "        ctg = np.concatenate([ctg1, np.asarray(v)])\n",
    "        cwtmatr, freqs = pywt.cwt(np.asarray(ctg), list(range(1, M)), 'cmor4-1.0')\n",
    "        if ma1 < np.absolute(np.max(cwtmatr)):\n",
    "            ma1 = np.absolute(np.max(cwtmatr))\n",
    "            best1 = (ma1, cwtmatr, k, v)\n",
    "        ctg = np.concatenate([np.asarray(v), ctg1])\n",
    "        cwtmatr, freqs = pywt.cwt(np.asarray(ctg), list(range(1, M)), 'cmor4-1.0')\n",
    "        if ma2 < np.absolute(np.max(cwtmatr)):\n",
    "            ma2 = np.absolute(np.max(cwtmatr))\n",
    "            best2 = (ma2, cwtmatr, k, v)\n",
    "\n",
    "    if best1[0] < best2[0]:\n",
    "        ctg1 = np.concatenate([np.asarray(best2[3]),ctg1])\n",
    "        best_list.append(best2[2])\n",
    "        #print(ctg1.shape)\n",
    "\n",
    "    else:\n",
    "        ctg1 = np.concatenate([ctg1, np.asarray(best1[3])])\n",
    "        best_list.append(best2[2])\n",
    "    \n",
    "    if len(best_list) > len(kmer_datas):\n",
    "        break\n",
    "    \n",
    "    if cnt % 10 == 0:\n",
    "        print(cnt // 10)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "cwtmatr, freqs = pywt.cwt(np.asarray(ctg1), list(range(1, M)), 'cmor4-1.0')\n",
    "plt.imshow(np.absolute(cwtmatr),  cmap='jet', aspect='auto',vmax=np.absolute(best[1]).max(), vmin=0)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "#plt.savefig(\"./temptemp.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ea5ddb4-14bd-43e1-a764-eb295e16328f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca138a8-f013-45a3-9e39-880d3ff856e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
